
[Executed at: Sun Oct 23 18:58:24 PDT 2022]

=======================================================
task2_2 starting
=======================================================
22/10/23 18:54:12 WARN Utils: Your hostname, ip-172-31-18-146 resolves to a loopback address: 127.0.0.1; using 172.31.18.146 instead (on interface ens5)
22/10/23 18:54:12 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
22/10/23 18:54:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/10/23 18:54:14 INFO SparkContext: Running Spark version 3.1.2
22/10/23 18:54:14 INFO ResourceUtils: ==============================================================
22/10/23 18:54:14 INFO ResourceUtils: No custom resources configured for spark.driver.
22/10/23 18:54:14 INFO ResourceUtils: ==============================================================
22/10/23 18:54:14 INFO SparkContext: Submitted application: task2.2
22/10/23 18:54:14 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/10/23 18:54:14 INFO ResourceProfile: Limiting resource is cpu
22/10/23 18:54:14 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/10/23 18:54:14 INFO SecurityManager: Changing view acls to: ccc_v1_g_7ea34_37383
22/10/23 18:54:14 INFO SecurityManager: Changing modify acls to: ccc_v1_g_7ea34_37383
22/10/23 18:54:14 INFO SecurityManager: Changing view acls groups to: 
22/10/23 18:54:14 INFO SecurityManager: Changing modify acls groups to: 
22/10/23 18:54:14 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_7ea34_37383); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_7ea34_37383); groups with modify permissions: Set()
22/10/23 18:54:14 INFO Utils: Successfully started service 'sparkDriver' on port 46533.
22/10/23 18:54:14 INFO SparkEnv: Registering MapOutputTracker
22/10/23 18:54:14 INFO SparkEnv: Registering BlockManagerMaster
22/10/23 18:54:14 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/10/23 18:54:14 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/10/23 18:54:14 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/10/23 18:54:14 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-721b5249-6cd2-4ab3-be63-6799c7ac4d10
22/10/23 18:54:14 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/10/23 18:54:14 INFO SparkEnv: Registering OutputCommitCoordinator
22/10/23 18:54:15 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
22/10/23 18:54:15 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
22/10/23 18:54:15 INFO Utils: Successfully started service 'SparkUI' on port 4042.
22/10/23 18:54:15 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.18.146:4042
22/10/23 18:54:15 INFO Executor: Starting executor ID driver on host 172.31.18.146
22/10/23 18:54:15 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45454.
22/10/23 18:54:15 INFO NettyBlockTransferService: Server created on 172.31.18.146:45454
22/10/23 18:54:15 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/10/23 18:54:15 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.18.146, 45454, None)
22/10/23 18:54:15 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.18.146:45454 with 366.3 MiB RAM, BlockManagerId(driver, 172.31.18.146, 45454, None)
22/10/23 18:54:15 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.18.146, 45454, None)
22/10/23 18:54:15 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.18.146, 45454, None)
finish feat
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,
             colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,
             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,
             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
             silent=True, subsample=1)
Duration:  69.53830575942993
check length True
val RMSE:  0.985628527713419
=======================================================
task2_3 starting
=======================================================
22/10/23 18:55:26 WARN Utils: Your hostname, ip-172-31-18-146 resolves to a loopback address: 127.0.0.1; using 172.31.18.146 instead (on interface ens5)
22/10/23 18:55:26 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
22/10/23 18:55:26 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties
22/10/23 18:55:28 INFO SparkContext: Running Spark version 3.1.2
22/10/23 18:55:28 INFO ResourceUtils: ==============================================================
22/10/23 18:55:28 INFO ResourceUtils: No custom resources configured for spark.driver.
22/10/23 18:55:28 INFO ResourceUtils: ==============================================================
22/10/23 18:55:28 INFO SparkContext: Submitted application: task2.2
22/10/23 18:55:28 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
22/10/23 18:55:28 INFO ResourceProfile: Limiting resource is cpu
22/10/23 18:55:28 INFO ResourceProfileManager: Added ResourceProfile id: 0
22/10/23 18:55:28 INFO SecurityManager: Changing view acls to: ccc_v1_g_7ea34_37383
22/10/23 18:55:28 INFO SecurityManager: Changing modify acls to: ccc_v1_g_7ea34_37383
22/10/23 18:55:28 INFO SecurityManager: Changing view acls groups to: 
22/10/23 18:55:28 INFO SecurityManager: Changing modify acls groups to: 
22/10/23 18:55:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ccc_v1_g_7ea34_37383); groups with view permissions: Set(); users  with modify permissions: Set(ccc_v1_g_7ea34_37383); groups with modify permissions: Set()
22/10/23 18:55:28 INFO Utils: Successfully started service 'sparkDriver' on port 46349.
22/10/23 18:55:28 INFO SparkEnv: Registering MapOutputTracker
22/10/23 18:55:28 INFO SparkEnv: Registering BlockManagerMaster
22/10/23 18:55:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
22/10/23 18:55:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
22/10/23 18:55:28 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
22/10/23 18:55:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-7e05b3fd-90ad-400e-b6d1-3c02c2293533
22/10/23 18:55:28 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
22/10/23 18:55:28 INFO SparkEnv: Registering OutputCommitCoordinator
22/10/23 18:55:29 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
22/10/23 18:55:29 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.
22/10/23 18:55:29 INFO Utils: Successfully started service 'SparkUI' on port 4042.
22/10/23 18:55:29 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://172.31.18.146:4042
22/10/23 18:55:29 INFO Executor: Starting executor ID driver on host 172.31.18.146
22/10/23 18:55:29 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 46352.
22/10/23 18:55:29 INFO NettyBlockTransferService: Server created on 172.31.18.146:46352
22/10/23 18:55:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
22/10/23 18:55:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 172.31.18.146, 46352, None)
22/10/23 18:55:29 INFO BlockManagerMasterEndpoint: Registering block manager 172.31.18.146:46352 with 366.3 MiB RAM, BlockManagerId(driver, 172.31.18.146, 46352, None)
22/10/23 18:55:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 172.31.18.146, 46352, None)
22/10/23 18:55:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 172.31.18.146, 46352, None)
Start precomputation....
Getting groupby rating dict...
def_rating 3.5
precomputation duration:  16.547417879104614
finish feat
XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,
             colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,
             max_depth=3, min_child_weight=1, missing=None, n_estimators=100,
             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,
             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,
             silent=True, subsample=1)
xgb prediction....
84.95010614395142
cf prediction an hybrid...
####
172.7087275981903
Duration:  173.0080463886261
check length True
val RMSE:  0.9866867415678797
=======================================================
task2_2 validation dataset pass
=======================================================
=======================================================
task2_3 validation dataset pass
=======================================================
